{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dacon_generator.ipynb","provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyPsysObcs4sR+2e7zCgZRpO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ffSo1J9QPbYJ","executionInfo":{"status":"ok","timestamp":1632803708006,"user_tz":-540,"elapsed":638,"user":{"displayName":"김기현","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0vGb-RRuguIMGp_5pQpeyFfEO9aqsaIduvpuV=s64","userId":"14783782336567567725"}},"outputId":"4a8c4c13-322c-416b-e241-d12e2da6f1c7"},"source":["from google.colab import drive\n","drive.mount('/gdrive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EHbRrkcAly8y","executionInfo":{"status":"ok","timestamp":1632803710387,"user_tz":-540,"elapsed":2382,"user":{"displayName":"김기현","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0vGb-RRuguIMGp_5pQpeyFfEO9aqsaIduvpuV=s64","userId":"14783782336567567725"}},"outputId":"5c360581-22a9-453b-80bb-cdf905a53dba"},"source":["from tensorflow.python.client import device_lib\n","device_lib.list_local_devices()"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[name: \"/device:CPU:0\"\n"," device_type: \"CPU\"\n"," memory_limit: 268435456\n"," locality {\n"," }\n"," incarnation: 1582377658696231737, name: \"/device:GPU:0\"\n"," device_type: \"GPU\"\n"," memory_limit: 16185556992\n"," locality {\n","   bus_id: 1\n","   links {\n","   }\n"," }\n"," incarnation: 6332918656603514006\n"," physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"]"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":618},"id":"TbuecIGirgDC","executionInfo":{"status":"ok","timestamp":1632803692463,"user_tz":-540,"elapsed":3633,"user":{"displayName":"김기현","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0vGb-RRuguIMGp_5pQpeyFfEO9aqsaIduvpuV=s64","userId":"14783782336567567725"}},"outputId":"473e6342-e95c-4c72-f4b2-af5c8787ebde"},"source":["!pip install imgaug --upgrade"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: imgaug in /usr/local/lib/python3.7/dist-packages (0.2.9)\n","Collecting imgaug\n","  Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n","\u001b[K     |████████████████████████████████| 948 kB 10.0 MB/s \n","\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from imgaug) (4.1.2.30)\n","Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug) (1.7.1)\n","Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from imgaug) (1.19.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug) (3.2.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug) (1.15.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from imgaug) (1.4.1)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug) (2.4.1)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from imgaug) (7.1.2)\n","Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from imgaug) (0.16.2)\n","Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug) (1.1.1)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug) (2.6.3)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug) (2.4.7)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug) (0.10.0)\n","Installing collected packages: imgaug\n","  Attempting uninstall: imgaug\n","    Found existing installation: imgaug 0.2.9\n","    Uninstalling imgaug-0.2.9:\n","      Successfully uninstalled imgaug-0.2.9\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.4.0 which is incompatible.\u001b[0m\n","Successfully installed imgaug-0.4.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["imgaug"]}}},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"TDC-4dlNPJz2","executionInfo":{"status":"ok","timestamp":1632803714533,"user_tz":-540,"elapsed":272,"user":{"displayName":"김기현","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0vGb-RRuguIMGp_5pQpeyFfEO9aqsaIduvpuV=s64","userId":"14783782336567567725"}}},"source":["# GPU 환경 설정\n","import os\n","# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n","\n","# 파일경로 설정\n","import json\n","\n","# 데이터 보기\n","import pandas as pd\n","import numpy as np\n","from glob import glob\n","\n","# 이미지데이터 로딩\n","import cv2\n","from tqdm import tqdm\n","\n","# Others\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","warnings.simplefilter('ignore')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"n8M_AwT5PwsG","executionInfo":{"status":"ok","timestamp":1632803717363,"user_tz":-540,"elapsed":728,"user":{"displayName":"김기현","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0vGb-RRuguIMGp_5pQpeyFfEO9aqsaIduvpuV=s64","userId":"14783782336567567725"}}},"source":["'''Generator'''\n","from tensorflow.keras.utils import Sequence\n","from google.colab.patches import cv2_imshow\n","from imgaug import augmenters as iaa\n","from imgaug.augmentables.batches import UnnormalizedBatch\n","\n","class Generator(Sequence):\n","    def __init__(self, src_path, input_shape, batch_size, augs=None, is_train=True):\n","        \n","        new_image_directory = src_path + '/new_images'\n","        new_train_image_directory = new_image_directory + '/train'\n","\n","        action_information = pd.read_csv(src_path + '/action_information.csv')\n","\n","        classes = pd.get_dummies(action_information[['Label']], columns = ['Label']).to_numpy()\n","        \n","        new_train_image_directories = sorted(glob(new_train_image_directory + '/*'), key = lambda x : int(x.split('/')[-1].split('_')[-1]))\n","\n","        train_answer = []\n","        train_image_directories = sorted(glob(new_train_image_directory + '/*'), key = lambda x : int(x.split('_')[-1]))\n","        for train_image_directory in train_image_directories : \n","            json_path = glob(train_image_directory + '/*.json')[0]\n","            js = json.load(open(json_path))\n","            action = js.get('action')\n","            train_answer.append(action)\n","        \n","        self.class_num = len(classes)\n","        self.is_train = is_train\n","        self.x_data = []\n","        self.y_data = []\n","        self.batch_size = batch_size\n","        self.input_shape = input_shape\n","        self.augs = iaa.Sequential(augs)\n","\n","        for new_train_image_directory, action in tqdm(zip(new_train_image_directories, train_answer), total = len(new_train_image_directories)) : \n","            image_paths = sorted(glob(new_train_image_directory + '/*.jpg'), key = lambda x : int(x.split('/')[-1].replace('.jpg','')))\n","            image_len = len(image_paths)\n","            self.x_data +=image_paths\n","            \n","            for i in range(image_len):\n","                self.y_data.append(classes[action])\n","\n","        self.on_epoch_end()\n","        print(\"Generator Initialized!!\")\n","    \n","    def __len__(self):\n","        return round(len(self.x_data) / self.batch_size)\n","    \n","    def __getitem__(self, idx):\n","        batch_x, batch_y = [], []\n","        batch_index = self.index[idx * self.batch_size:(idx+1)*self.batch_size]\n","        \n","        for batch_i in batch_index:\n","            batch_x.append(self.x_data[batch_i])\n","            batch_y.append(self.y_data[batch_i])\n","        \n","        out_x, out_y = self.data_gen(batch_x, batch_y)\n","        return out_x, out_y\n","\n","    def on_epoch_end(self):\n","        self.index = np.arange(len(self.x_data))\n","        if self.is_train:\n","            np.random.shuffle(self.index)\n","    \n","    def data_gen(self, x ,y):\n","        input_x = np.zeros((self.batch_size, self.input_shape[0], self.input_shape[1], 3), dtype=np.float)\n","        input_y = np.zeros((self.batch_size, self.class_num), dtype=np.float)\n","\n","        imgs = []\n","        for i in range(len(x)):\n","            img = cv2.imread(x[i])\n","            imgs.append(cv2.resize(img, (self.input_shape[0], self.input_shape[1])))\n","        \n","        batch_imgs = UnnormalizedBatch(images=imgs, data=y)\n","        batch_aug_imgs = list(self.augs.augment_batches(batches=batch_imgs))\n","\n","        for i in range(len(x)):\n","            aug_img = batch_aug_imgs[0].images_aug[i]\n","            input_x[i]= aug_img.astype(np.float) / 255.0\n","            input_y[i] = y[i]\n","        return input_x, input_y\n","        \n"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"KecP5uCOYWrM","executionInfo":{"status":"ok","timestamp":1632803720408,"user_tz":-540,"elapsed":386,"user":{"displayName":"김기현","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0vGb-RRuguIMGp_5pQpeyFfEO9aqsaIduvpuV=s64","userId":"14783782336567567725"}}},"source":["from tensorflow.keras.applications import EfficientNetB2 # 모델은 가벼운 모델을 사용합니다.\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.models import Model\n","\n","def buildModel():\n","    baseModel = EfficientNetB2(input_shape = (224,224,3), weights='imagenet', include_top=False, )\n","    baseModel.trainable = True\n","    model_in = Input(shape = (224,224,3))\n","    base_model = baseModel(model_in)\n","    head_model = MaxPooling2D(pool_size=(7, 7))(base_model)\n","    head_model = Flatten(name=\"flatten\")(head_model)\n","    head_model = Dense(256, activation = 'relu')(head_model)\n","    head_model = Dropout(0.2)(head_model)\n","    head_model = Dense(32, activation = 'relu')(head_model)\n","    head_model = Dropout(0.2)(head_model)\n","    head_model = Dense(8, activation = 'relu')(head_model)\n","    head_model = Dropout(0.2)(head_model)\n","    model_out = Dense(6, activation=\"softmax\")(head_model)\n","\n","    model = Model(inputs=model_in, outputs=model_out)\n","    return model"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"PEB3bgtjqQge","executionInfo":{"status":"ok","timestamp":1632803722067,"user_tz":-540,"elapsed":366,"user":{"displayName":"김기현","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0vGb-RRuguIMGp_5pQpeyFfEO9aqsaIduvpuV=s64","userId":"14783782336567567725"}}},"source":["import imgaug.augmenters as iaa\n","\n","augs =[\n","       iaa.Fliplr(0.5),\n","       \n","        iaa.Sometimes(0.2,iaa.Sharpen()),\n","       \n","        iaa.SomeOf((1,2),[\n","            iaa.MultiplyAndAddToBrightness(),\n","            iaa.GammaContrast()\n","        ]),\n","\n","        iaa.SomeOf((0,1), [\n","            iaa.Sometimes(0.7, iaa.AdditiveGaussianNoise()),\n","            iaa.Sometimes(0.7, iaa.GaussianBlur())\n","        ]),\n","\n","        iaa.SomeOf((0,8),[\n","            iaa.ShearX(),\n","            iaa.ShearY(),\n","            iaa.ScaleX(),\n","            iaa.ScaleY(),\n","            iaa.TranslateX(),\n","            iaa.TranslateY(),\n","            iaa.Sometimes(0.3, iaa.Affine()),\n","            iaa.Sometimes(0.3, iaa.PerspectiveTransform()),\n","        ]),\n","\n","        iaa.SomeOf((0,1),[\n","            iaa.Sometimes(0.6, iaa.Dropout()),\n","            iaa.Sometimes(0.6, iaa.CoarseDropout()),\n","            iaa.Sometimes(0.6, iaa.Cutout())\n","        ])\n","]"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LrsHxoUcfNqt","outputId":"198f78de-e7c3-462e-d36c-73cc250d3a89"},"source":["# Modeling\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.optimizers import SGD\n","from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n","\n","'''Train options'''\n","src_path = '/gdrive/MyDrive/dacon/handSignal'\n","batch_size = 64\n","input_shape = (224, 224)\n","epochs = 2000\n","lr = 1e-3\n","model_name = \"effient\"\n","filename = src_path+\"/save_weights/%s_{epoch:05d}.h5\"%(model_name)\n","\n","callback = [ReduceLROnPlateau(monitor='loss', factor=0.1, patience=3),\n","            ModelCheckpoint(filename, monitor=\"loss\", save_best_only=True)]\n","\n","'''Build Model'''\n","with tf.device('/device:GPU:0'):\n","    model = buildModel()\n","\n","    model.compile(loss='categorical_crossentropy',optimizer=SGD(learning_rate=lr, momentum=0.9), metrics=['accuracy'])\n","\n","\n","    '''Train'''\n","    train_gen = Generator(src_path, input_shape, batch_size, augs=augs, is_train=True)\n","    model.fit_generator(train_gen, epochs=epochs, max_queue_size=50, workers=32, callbacks=callback)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 142/142 [00:00<00:00, 494.81it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Generator Initialized!!\n","Epoch 1/2000\n","347/347 [==============================] - 244s 640ms/step - loss: 1.8159 - accuracy: 0.1769\n","Epoch 2/2000\n"," 49/347 [===>..........................] - ETA: 3:12 - loss: 1.7931 - accuracy: 0.1712"]}]},{"cell_type":"code","metadata":{"id":"AN_BPbBcpFlL","executionInfo":{"status":"aborted","timestamp":1632777267598,"user_tz":-540,"elapsed":309,"user":{"displayName":"김기현","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0vGb-RRuguIMGp_5pQpeyFfEO9aqsaIduvpuV=s64","userId":"14783782336567567725"}}},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PtYeR-TndYNW"},"source":["'''for test generator'''\n","src_path = '/gdrive/MyDrive/dacon/handSignal'\n","batch_size = 1\n","input_shape = (224, 224)\n","gen = Generator(src_path, input_shape, batch_size, is_train=True)\n","gen.__getitem__(0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"11Z3ZKIlQitL"},"source":["# Prediction"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3a8h-GX2QlIJ","executionInfo":{"status":"ok","timestamp":1632800918303,"user_tz":-540,"elapsed":1997765,"user":{"displayName":"김기현","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0vGb-RRuguIMGp_5pQpeyFfEO9aqsaIduvpuV=s64","userId":"14783782336567567725"}},"outputId":"725b16be-c53f-49a9-de28-e71f06276b99"},"source":["src_path = '/gdrive/MyDrive/dacon/handSignal'\n","\n","new_test_image_directory = src_path + '/new_images/test'\n","new_test_image_directories = sorted(glob(new_test_image_directory + '/*'), key = lambda x : int(x.split('file_')[-1]))\n","model = buildModel()\n","model.load_weights(src_path+\"/save_weights/effient_00049.h5\")\n","\n","predictions = []\n","for new_test_image_directory in tqdm(new_test_image_directories, total = len(new_test_image_directories)) :\n","    image_paths = sorted(glob(new_test_image_directory + '/*.jpg'), key = lambda x : int(x.split('/')[-1].replace('.jpg','')))\n","    image_len = len(image_paths)\n","    test_images  = []\n","    for image_path in image_paths:\n","        img = cv2.imread(image_path)\n","        img = cv2.resize(img, (224, 224))\n","        img = img/255\n","        test_images.append(img)\n","    prediction = np.mean(model.predict(np.array(test_images)), axis = 0)\n","    predictions.append(prediction)"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 45/45 [33:14<00:00, 44.31s/it]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"p6VBAqminuFh","executionInfo":{"status":"ok","timestamp":1632802678756,"user_tz":-540,"elapsed":411,"user":{"displayName":"김기현","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0vGb-RRuguIMGp_5pQpeyFfEO9aqsaIduvpuV=s64","userId":"14783782336567567725"}},"outputId":"dc26c820-b953-4ff8-8f9d-b9275f23f57d"},"source":["sample_submission = pd.read_csv(src_path + '/sample_submission.csv')\n","sample_submission.iloc[:,1:] = predictions\n","display(sample_submission.head())\n","sample_submission.to_csv(src_path+'/BASELINE.csv', index=False)"],"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>file_path</th>\n","      <th>Label_0</th>\n","      <th>Label_1</th>\n","      <th>Label_2</th>\n","      <th>Label_3</th>\n","      <th>Label_4</th>\n","      <th>Label_5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>./test\\file_142</td>\n","      <td>1.870417e-06</td>\n","      <td>0.000014</td>\n","      <td>0.681942</td>\n","      <td>0.294948</td>\n","      <td>0.022918</td>\n","      <td>0.000176</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>./test\\file_143</td>\n","      <td>1.283897e-04</td>\n","      <td>0.004398</td>\n","      <td>0.080832</td>\n","      <td>0.007422</td>\n","      <td>0.009238</td>\n","      <td>0.897982</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>./test\\file_144</td>\n","      <td>2.673115e-07</td>\n","      <td>0.000094</td>\n","      <td>0.074797</td>\n","      <td>0.916459</td>\n","      <td>0.008077</td>\n","      <td>0.000572</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>./test\\file_145</td>\n","      <td>5.199605e-09</td>\n","      <td>0.002207</td>\n","      <td>0.884185</td>\n","      <td>0.000071</td>\n","      <td>0.000390</td>\n","      <td>0.113147</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>./test\\file_146</td>\n","      <td>8.309455e-01</td>\n","      <td>0.154915</td>\n","      <td>0.000901</td>\n","      <td>0.000104</td>\n","      <td>0.011386</td>\n","      <td>0.001749</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         file_path       Label_0   Label_1  ...   Label_3   Label_4   Label_5\n","0  ./test\\file_142  1.870417e-06  0.000014  ...  0.294948  0.022918  0.000176\n","1  ./test\\file_143  1.283897e-04  0.004398  ...  0.007422  0.009238  0.897982\n","2  ./test\\file_144  2.673115e-07  0.000094  ...  0.916459  0.008077  0.000572\n","3  ./test\\file_145  5.199605e-09  0.002207  ...  0.000071  0.000390  0.113147\n","4  ./test\\file_146  8.309455e-01  0.154915  ...  0.000104  0.011386  0.001749\n","\n","[5 rows x 7 columns]"]},"metadata":{}}]}]}